{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Activation\n",
    "from tensorflow.keras.optimizers import RMSprop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open(path, 'rb').read().decode(encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\n': 0, ' ': 1, '!': 2, '$': 3, '&': 4, \"'\": 5, ',': 6, '-': 7, '.': 8, '3': 9, ':': 10, ';': 11, '?': 12, 'A': 13, 'B': 14, 'C': 15, 'D': 16, 'E': 17, 'F': 18, 'G': 19, 'H': 20, 'I': 21, 'J': 22, 'K': 23, 'L': 24, 'M': 25, 'N': 26, 'O': 27, 'P': 28, 'Q': 29, 'R': 30, 'S': 31, 'T': 32, 'U': 33, 'V': 34, 'W': 35, 'X': 36, 'Y': 37, 'Z': 38, 'a': 39, 'b': 40, 'c': 41, 'd': 42, 'e': 43, 'f': 44, 'g': 45, 'h': 46, 'i': 47, 'j': 48, 'k': 49, 'l': 50, 'm': 51, 'n': 52, 'o': 53, 'p': 54, 'q': 55, 'r': 56, 's': 57, 't': 58, 'u': 59, 'v': 60, 'w': 61, 'x': 62, 'y': 63, 'z': 64}\n",
      "{0: '\\n', 1: ' ', 2: '!', 3: '$', 4: '&', 5: \"'\", 6: ',', 7: '-', 8: '.', 9: '3', 10: ':', 11: ';', 12: '?', 13: 'A', 14: 'B', 15: 'C', 16: 'D', 17: 'E', 18: 'F', 19: 'G', 20: 'H', 21: 'I', 22: 'J', 23: 'K', 24: 'L', 25: 'M', 26: 'N', 27: 'O', 28: 'P', 29: 'Q', 30: 'R', 31: 'S', 32: 'T', 33: 'U', 34: 'V', 35: 'W', 36: 'X', 37: 'Y', 38: 'Z', 39: 'a', 40: 'b', 41: 'c', 42: 'd', 43: 'e', 44: 'f', 45: 'g', 46: 'h', 47: 'i', 48: 'j', 49: 'k', 50: 'l', 51: 'm', 52: 'n', 53: 'o', 54: 'p', 55: 'q', 56: 'r', 57: 's', 58: 't', 59: 'u', 60: 'v', 61: 'w', 62: 'x', 63: 'y', 64: 'z'}\n"
     ]
    }
   ],
   "source": [
    "charcters = sorted(set(text))\n",
    "charcters_indices = dict((c, i) for i, c in enumerate(charcters))\n",
    "indices_charcters = dict((i, c) for i, c in enumerate(charcters))\n",
    "print(charcters_indices)\n",
    "print(indices_charcters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len =  40\n",
    "stp_size = 3\n",
    "\n",
    "sentences = []\n",
    "next_chars = []\n",
    "\n",
    "for i in range(0, len(text) - seq_len, stp_size):\n",
    "    sentences.append(text[i: i + seq_len])\n",
    "    next_chars.append(text[i + seq_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = np.zeros((len(sentences), seq_len, len(charcters)), dtype=bool)\n",
    "y = np.zeros((len(sentences), len(charcters)), dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, charcters_indices[char]] = 1\n",
    "    y[i, charcters_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(seq_len, len(charcters))))\n",
    "model.add(Dense(len(charcters)))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=0.01), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5810/5810 [==============================] - 61s 10ms/step - loss: 1.8760 - accuracy: 0.4580\n",
      "Epoch 2/10\n",
      "5810/5810 [==============================] - 59s 10ms/step - loss: 1.6470 - accuracy: 0.5177\n",
      "Epoch 3/10\n",
      "5810/5810 [==============================] - 59s 10ms/step - loss: 1.5960 - accuracy: 0.5317\n",
      "Epoch 4/10\n",
      "5810/5810 [==============================] - 59s 10ms/step - loss: 1.5717 - accuracy: 0.5388\n",
      "Epoch 5/10\n",
      "5810/5810 [==============================] - 60s 10ms/step - loss: 1.5520 - accuracy: 0.5433\n",
      "Epoch 6/10\n",
      "5810/5810 [==============================] - 60s 10ms/step - loss: 1.5410 - accuracy: 0.5460\n",
      "Epoch 7/10\n",
      "5810/5810 [==============================] - 58s 10ms/step - loss: 1.5358 - accuracy: 0.5480\n",
      "Epoch 8/10\n",
      "5810/5810 [==============================] - 58s 10ms/step - loss: 1.5320 - accuracy: 0.5490\n",
      "Epoch 9/10\n",
      "5810/5810 [==============================] - 57s 10ms/step - loss: 1.5332 - accuracy: 0.5489\n",
      "Epoch 10/10\n",
      "5810/5810 [==============================] - 57s 10ms/step - loss: 1.5357 - accuracy: 0.5496\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13ed3fce620>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y, batch_size=64, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('shakesper.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('shakesper.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genrate_text(length, temperature):\n",
    "    start_index = random.randint(0, len(text) - seq_len - 1)\n",
    "    generated = ''\n",
    "    sentence = text[start_index: start_index + seq_len]\n",
    "    generated += sentence\n",
    "    for i in range(length):\n",
    "        x_pred = np.zeros((1, seq_len, len(charcters)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x_pred[0, t, charcters_indices[char]] = 1\n",
    "        preds = model.predict(x_pred, verbose=0)[0]\n",
    "        next_index = sample(preds, temperature)\n",
    "        next_char = indices_charcters[next_index]\n",
    "        generated += next_char\n",
    "        sentence = sentence[1:] + next_char\n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________\n",
      "at loves not me, nor none of you.\n",
      "\n",
      "RIVEREY:\n",
      "I will thou shall be the man in the straight.\n",
      "\n",
      "CORIOLANUS:\n",
      "I will thou show the man, and the man and the fair son of the man.\n",
      "\n",
      "CORIOLANUS:\n",
      "I have the man and the man and the man.\n",
      "\n",
      "CORIOLANUS:\n",
      "I will not shall be the man and the man.\n",
      "\n",
      "GLOUCESTER:\n",
      "The man and the man and the man and the man.\n",
      "\n",
      "GLOU\n",
      "__________________________________________________________\n",
      "en forget himself?\n",
      "\n",
      "First Huntsman:\n",
      "Belike, sir, I will she and the man, the fair sick of the comples,\n",
      "That the brother and the man and the man.\n",
      "\n",
      "CORIOLANUS:\n",
      "I would not shall be the many the brother\n",
      "And the man and the father and the man.\n",
      "\n",
      "GLOUCESTER:\n",
      "The man and the man and the brother and the fair son,\n",
      "And the man and the brother and t\n",
      "__________________________________________________________\n",
      "Turks and infidels,\n",
      "And in this seat of the seast of the grace.\n",
      "\n",
      "CORIOLANUS:\n",
      "I have the better and the man and the man.\n",
      "\n",
      "CORIOLANUS:\n",
      "I am the man, the man, and the man and the grace\n",
      "That he will be the man and the man and the man.\n",
      "\n",
      "CORIOLANUS:\n",
      "I have the seast that the brother is the brother\n",
      "And the brother and the brother and the man.\n",
      "\n",
      "C\n",
      "__________________________________________________________\n",
      " as much.\n",
      "\n",
      "LUCENTIO:\n",
      "Preposterous ass, the man and the man and the brother\n",
      "And the man and the man and the man and the comple,\n",
      "And the man and the man and the brothers.\n",
      "\n",
      "CORIOLANUS:\n",
      "I have the man, the come of the straight.\n",
      "\n",
      "CORIOLANUS:\n",
      "I will not shall be the brother and the man.\n",
      "\n",
      "BIOND:\n",
      "I will thou she will be the man to the brother\n",
      "And\n",
      "__________________________________________________________\n",
      "which late I noted\n",
      "In tatter'd weeds, with him to the straight.\n",
      "\n",
      "CORIOLANUS:\n",
      "I will not she with him to the seas, and be the brother\n",
      "And the man and the man and the man and the brother.\n",
      "\n",
      "BIOND:\n",
      "I will thou she will be the brother and the man.\n",
      "\n",
      "CORIOLANUS:\n",
      "I have the man and the brother and the straight.\n",
      "\n",
      "CORIOLANUS:\n",
      "I am the brother and t\n"
     ]
    }
   ],
   "source": [
    "print(\"__________________________________________________________\")\n",
    "print(genrate_text(300, 0.76))\n",
    "print(\"__________________________________________________________\")\n",
    "print(genrate_text(300, 0.4))\n",
    "print(\"__________________________________________________________\")\n",
    "print(genrate_text(300, 0.1))\n",
    "print(\"__________________________________________________________\")\n",
    "print(genrate_text(300, 0.3))\n",
    "print(\"__________________________________________________________\")\n",
    "print(genrate_text(300, 0.9))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpupy10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
